#!/usr/bin/env python

# coding=utf-8

"""
THIS FILE WAS INSTALLED BY CHEF.  ANY CHANGES WILL BE OVERWRITTEN.

Openstack swift collector for recon and dispersion reports.  Will send
back dispersion reporting metrics as well as swift recon statistics
to a statsd server for graphite consumption
"""

from subprocess import Popen, PIPE, check_call
from socket import socket, AF_INET, SOCK_DGRAM
import re
import os

try:
    import json
    json  # workaround for pyflakes issue #13
except ImportError:
    import simplejson as json


class OpenStackSwiftStatisticsCollector(object):

    def __init__(self):
        '''Setup some initial values defined by chef'''

        self.statsd_host              = '<%= node[:swift][:statistics][:statsd_host] %>'
        self.statsd_port              = <%= node[:swift][:statistics][:statsd_port] %>
        self.statsd_prefix	      = '<%= node[:swift][:statistics][:statsd_prefix] %>'
<% if node[:swift][:statistics][:enable_dispersion_report] -%>
        self.enable_dispersion_report = True
<% else %>
        self.enable_dispersion_report = False
<% end %>
<% if node[:swift][:statistics][:enable_recon_report] -%>
        self.enable_recon_report      = True
<% else %>
        self.enable_recon_report      = False
<% end %>
<% if node[:swift][:statistics][:enable_disk_report] -%>
        self.enable_disk_report      = True
<% else %>
        self.enable_disk_report      = False
<% end %>
        self.recon_account_cache      = '<%= node[:swift][:statistics][:recon_account_cache] %>'
        self.recon_container_cache    = '<%= node[:swift][:statistics][:recon_container_cache] %>'
        self.recon_object_cache       = '<%= node[:swift][:statistics][:recon_object_cache] %>'

    def collect(self):

        #-------------------------------
        # dispersion report collection
        #-------------------------------

        if (self.enable_dispersion_report):
            p = Popen(['/usr/bin/swift-dispersion-report', '-j'],
                stdout=PIPE, stderr=PIPE)
            stdout, stderr = p.communicate()
            self.publish('%s.dispersion.errors' % self.statsd_prefix, len(stderr.split('\n')) - 1)
            data = json.loads(stdout)
            for t in ('object', 'container'):
                for (k, v) in data[t].items():
                    self.publish('%s.dispersion.%s.%s' % (self.statsd_prefix, t, k), v)

        #-------------------------------
        # swift recon collection
        #-------------------------------

        if (self.enable_recon_report):

            self.metrics = []
            recon_cache = {'account': self.recon_account_cache,
                           'container': self.recon_container_cache,
                           'object': self.recon_object_cache}
            for recon_type in recon_cache:
                if not os.access(recon_cache[recon_type], os.R_OK):
                    continue
                try:
                    f = open(recon_cache[recon_type])
                    try:
                        rmetrics = json.loads(f.readlines()[0].strip())
                        self.metrics = []
                        self._process_cache(rmetrics)
                        for k, v in self.metrics:
                            metric_name = '%s.%s.%s' % (self.statsd_prefix, recon_type, ".".join(k))
                            if isinstance(v, (int, float)):
                                self.publish(metric_name, v)
                    except (ValueError, IndexError):
                        continue
                finally:
                    f.close()

        #-------------------------------
        # swift disk collection
        #-------------------------------

        if (self.enable_disk_report):

            p = Popen(['/usr/bin/swift-recon', '-d'],
                stdout=PIPE, stderr=PIPE)
            stdout, stderr = p.communicate()

            used, total = 0, 0
            match = re.search(r'.* space used: ([0-9]*\.?[0-9]+) of ([0-9]*\.?[0-9]+)', stdout, re.M|re.I)
            if match:
                used, total = [int(i) for i in match.groups()]

            highest, avg = 0, 0
            match = re.search(r'.* lowest:.+highest: ([0-9]*\.?[0-9]+)%, avg: ([0-9]*\.?[0-9]+)%', stdout, re.M|re.I)
            if match:
                highest, avg = match.groups()

            self.publish('%s.capacity.bytes_used' % self.statsd_prefix, used)
            self.publish('%s.capacity.bytes_free' % self.statsd_prefix, total-used)
            self.publish('%s.capacity.bytes_utilization' % self.statsd_prefix, int((used/total)*100))
            self.publish('%s.capacity.single_disk_utililization_highest' % self.statsd_prefix, highest)
            self.publish('%s.capacity.single_disk_utililization_average' % self.statsd_prefix, avg)

    def publish(self, metric_name, value):
        """Publish a metric to statsd server"""
        # TODO: IPv6 support
        print '%s:%s|g' % (metric_name.encode('utf-8'), value), (self.statsd_host, self.statsd_port)
        udp_sock = socket(AF_INET, SOCK_DGRAM)
        udp_sock.sendto('%s:%s|g' % (metric_name.encode('utf-8'), value), (self.statsd_host, self.statsd_port))

    def _process_cache(self, d, path=()):
        """Recusively walk a nested recon cache dict to obtain path/values"""
        for k, v in d.iteritems():
            if not isinstance(v, dict):
                self.metrics.append((path + (k,), v))
            else:
                self._process_cache(v, path + (k,))

if __name__ == '__main__':
    collector =  OpenStackSwiftStatisticsCollector()
    collector.collect()
